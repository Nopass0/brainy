# üß† Brainy

**–ë—ã—Å—Ç—Ä—ã–π AI/ML —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è Bun (TypeScript) —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π GPU/CPU**

Brainy ‚Äî —ç—Ç–æ –ø–æ–ª–Ω–æ—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –≤–¥–æ—Ö–Ω–æ–≤–ª—ë–Ω–Ω—ã–π PyTorch, –Ω–∞–ø–∏—Å–∞–Ω–Ω—ã–π –Ω–∞ —á–∏—Å—Ç–æ–º TypeScript –¥–ª—è Bun runtime.

## ‚ú® –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

- **–¢–µ–Ω–∑–æ—Ä–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏** ‚Äî –º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã–µ –º–∞—Å—Å–∏–≤—ã —Å broadcasting
- **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏–µ** ‚Äî –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π autograd
- **–ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ —Å–ª–æ–∏** ‚Äî Linear, Conv2d, LSTM, Embedding, BatchNorm, LayerNorm, Dropout
- **–ê–∫—Ç–∏–≤–∞—Ü–∏–∏** ‚Äî ReLU, GELU, Sigmoid, Softmax, Tanh, SiLU, –∏ –¥—Ä—É–≥–∏–µ
- **–§—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å** ‚Äî MSE, CrossEntropy, BCE, NLL, Hinge, KLDiv
- **–û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã** ‚Äî SGD, Adam, AdamW, RMSprop, Adagrad
- **LR Schedulers** ‚Äî StepLR, CosineAnnealing, ReduceLROnPlateau
- **Data utilities** ‚Äî Dataset, DataLoader, train/test split
- **–°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è** ‚Äî —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π

## üì¶ –£—Å—Ç–∞–Ω–æ–≤–∫–∞

```bash
# –ö–ª–æ–Ω–∏—Ä—É–π—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
git clone <repo-url>
cd brainy

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
bun install
```

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

```typescript
import { tensor, Linear, MSELoss, SGD } from './src';

// –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ–Ω–∑–æ—Ä–∞
const x = tensor([[1, 2, 3], [4, 5, 6]]);
console.log(x.shape); // [2, 3]

// –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
const y = x.mul(2).add(1);
console.log(y.toArray()); // [[3, 5, 7], [9, 11, 13]]

// –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å
const model = new Linear(10, 5);
const criterion = new MSELoss();
const optimizer = new SGD(model.parameters(), 0.01);

// –û–±—É—á–µ–Ω–∏–µ
const input = tensor([...Array(10)].map(() => Math.random()));
const target = tensor([...Array(5)].map(() => Math.random()));

for (let i = 0; i < 100; i++) {
  const output = model.forward(input);
  const loss = criterion.forward(output, target);
  
  optimizer.zeroGrad();
  loss.backward();
  optimizer.step();
}
```

## üìö –ü—Ä–∏–º–µ—Ä—ã

```bash
# –ë–∞–∑–æ–≤—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å —Ç–µ–Ω–∑–æ—Ä–∞–º–∏
bun run examples/01-basic-tensors.ts

# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏–µ
bun run examples/02-autograd.ts

# –õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è
bun run examples/03-linear-regression.ts

# XOR –Ω–µ–π—Ä–æ—Å–µ—Ç—å
bun run examples/04-xor-neural-network.ts

# MNIST –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è (CNN)
bun run examples/05-mnist-classification.ts

# –ö–∞—Å—Ç–æ–º–Ω—ã–µ —Å–ª–æ–∏ (Attention, ResNet)
bun run examples/06-custom-layer.ts
```

## üèóÔ∏è API Reference

### –¢–µ–Ω–∑–æ—Ä—ã

```typescript
// –°–æ–∑–¥–∞–Ω–∏–µ
tensor([[1, 2], [3, 4]])      // –ò–∑ –º–∞—Å—Å–∏–≤–∞
zeros([2, 3])                  // –ù—É–ª–∏
ones([2, 3])                   // –ï–¥–∏–Ω–∏—Ü—ã
rand([2, 3])                   // –°–ª—É—á–∞–π–Ω—ã–µ [0, 1)
randn([2, 3])                  // –ù–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
eye(3)                         // –ï–¥–∏–Ω–∏—á–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞
linspace(0, 10, 5)             // –õ–∏–Ω–µ–π–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
arange(0, 10, 2)               // –î–∏–∞–ø–∞–∑–æ–Ω

// –û–ø–µ—Ä–∞—Ü–∏–∏
t.add(other)                   // –°–ª–æ–∂–µ–Ω–∏–µ
t.sub(other)                   // –í—ã—á–∏—Ç–∞–Ω–∏–µ
t.mul(other)                   // –£–º–Ω–æ–∂–µ–Ω–∏–µ (–ø–æ—ç–ª–µ–º–µ–Ω—Ç–Ω–æ–µ)
t.div(other)                   // –î–µ–ª–µ–Ω–∏–µ
t.matmul(other)                // –ú–∞—Ç—Ä–∏—á–Ω–æ–µ —É–º–Ω–æ–∂–µ–Ω–∏–µ
t.pow(2)                       // –°—Ç–µ–ø–µ–Ω—å
t.exp()                        // –≠–∫—Å–ø–æ–Ω–µ–Ω—Ç–∞
t.log()                        // –õ–æ–≥–∞—Ä–∏—Ñ–º

// Reshape
t.reshape(3, 4)                // –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ñ–æ—Ä–º—ã
t.flatten()                    // –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ
t.transpose(0, 1)              // –¢—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
t.squeeze()                    // –£–¥–∞–ª–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π=1
t.unsqueeze(0)                 // –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏

// –†–µ–¥—É–∫—Ü–∏–∏
t.sum()                        // –°—É–º–º–∞
t.mean()                       // –°—Ä–µ–¥–Ω–µ–µ
t.max()                        // –ú–∞–∫—Å–∏–º—É–º
t.min()                        // –ú–∏–Ω–∏–º—É–º
t.argmax()                     // –ò–Ω–¥–µ–∫—Å –º–∞–∫—Å–∏–º—É–º–∞
```

### –ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏

```typescript
import { Sequential, Linear, ReLU, Conv2d, Dropout } from './src';

const model = new Sequential(
  new Linear(784, 256),
  new ReLU(),
  new Dropout(0.5),
  new Linear(256, 10)
);

const output = model.forward(input);
```

### –û–±—É—á–µ–Ω–∏–µ

```typescript
import { CrossEntropyLoss, Adam } from './src';

const criterion = new CrossEntropyLoss();
const optimizer = new Adam(model.parameters(), 0.001);

for (const batch of dataLoader) {
  const output = model.forward(batch.input);
  const loss = criterion.forward(output, batch.target);
  
  optimizer.zeroGrad();
  loss.backward();
  optimizer.step();
}
```

### –ö–∞—Å—Ç–æ–º–Ω—ã–µ —Å–ª–æ–∏

```typescript
import { Module, Parameter, Linear, Tensor } from './src';

class MyLayer extends Module {
  weight: Parameter;
  linear: Linear;

  constructor(inFeatures: number, outFeatures: number) {
    super();
    this.weight = new Parameter(randn([inFeatures]), 'weight');
    this.linear = new Linear(inFeatures, outFeatures);
    
    this.registerParameter('weight', this.weight);
    this.registerModule('linear', this.linear);
  }

  forward(x: Tensor): Tensor {
    return this.linear.forward(x.mul(this.weight.data));
  }
}
```

## üìÇ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
brainy/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ core/           # –¢–µ–Ω–∑–æ—Ä—ã –∏ autograd
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tensor.ts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autograd.ts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dtype.ts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ shape.ts
‚îÇ   ‚îú‚îÄ‚îÄ nn/             # –ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ –º–æ–¥—É–ª–∏
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ module.ts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ layers.ts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ activations.ts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ loss.ts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ init.ts
‚îÇ   ‚îú‚îÄ‚îÄ optim/          # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ optimizer.ts
‚îÇ   ‚îú‚îÄ‚îÄ data/           # Data utilities
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dataloader.ts
‚îÇ   ‚îú‚îÄ‚îÄ functional/     # –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π API
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ functional.ts
‚îÇ   ‚îú‚îÄ‚îÄ utils/          # –£—Ç–∏–ª–∏—Ç—ã
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ serialize.ts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ random.ts
‚îÇ   ‚îî‚îÄ‚îÄ index.ts        # –ì–ª–∞–≤–Ω—ã–π —ç–∫—Å–ø–æ—Ä—Ç
‚îú‚îÄ‚îÄ examples/           # –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
‚îî‚îÄ‚îÄ package.json
```

## üîß –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å PyTorch

| PyTorch | Brainy |
|---------|--------|
| `torch.tensor([1, 2, 3])` | `tensor([1, 2, 3])` |
| `torch.zeros(2, 3)` | `zeros([2, 3])` |
| `x @ y` | `x.matmul(y)` |
| `nn.Linear(10, 5)` | `new Linear(10, 5)` |
| `nn.Sequential(...)` | `new Sequential(...)` |
| `optim.Adam(...)` | `new Adam(...)` |
| `loss.backward()` | `loss.backward()` |

## üìÑ –õ–∏—Ü–µ–Ω–∑–∏—è

MIT License
